# 3.神经网络预测导论：向前传播

## 3.3 单个神经网络

### Basic

- 神经网络的交互原理

  接受输入的变量，将此变量作为信息来源；拥有权重变量，将此作为知识；融合信息和知识，输出预测结果。

### Implementation

- Prediction of single feature

  ```python
  import numpy as np;
  # Neural network code
  weight = 0.1;
  def neural_network(input, weight):
      prediction = input * weight;
      return prediction;
  # Prediction
  number_of_toe = [8.5, 9.5, 10, 9];
  input = number_of_toe[0];
  pred = neural_network(input,weight);
  print(pred);
  ```

## 3.6 多个输入

### Basic

- 加权和（又称为点积）

  - Definition

    每个输入乘以各自的权重，然后对所有局部预测结果进行求和后得到的结果。

  - Use

    显示两个向量之间的相似性。

- 逐元素(Element wise)操作

  - Definition

    两个长度相等的向量之间，把元素按照对应的位置进行配对，并进行数学运算。

- Attention

  - 不能打乱权重的顺序。

  - 权重值和输入值共同决定了对最终打分的影响

    <!--如果权重值低，输入值高，依旧会产生高分-->

  - 负的权重值会导致最终预测结果随着输入值的增加而减少

### Implementation

- Prediction of multiple features

  ```python
  import numpy as np;
  # Neural network code
  def w_sum(a,b):
      assert (len(a) == len(b));
      output = 0;
      for i in range(len(a)):
          output += (a[i] * b[i]);
      return output;
  
  weights = [0.1, 0.2, 0];
  def neural_network(input, weights):
      pred = w_sum(input, weights);
      return pred;
  
  # Data
  toes = [8.5, 9.5, 9.9, 9.0];
  wlrec = [0.65, 0.8, 0.8, 0.9];
  nfans = [1.2, 1.3, 0.5, 1.0];
  
  # Calculate
  input = [toes[0], wlrec[0], nfans[0]]
  pred = neural_network(input, weights);
  print(pred); 
  ```

- Challenge of Vector

  ```python
  import numpy as np;
  
  # Elementwise_multiplication(vec_a, vec_b)
  def elementwise_multiplication(vec_a, vec_b):
      assert (len(vec_a) == len(vec_b));
      for i in range(len(vec_a)):
          vec_a[i] = (vec_a[i] * vec_b[i]);
      return vec_a;
  
  # Elementwise_addition(vec_a, vec_b)
  def elementwise_addition(vec_a, vec_b):
      assert (len(vec_a) == len(vec_b));
      for i in range(len(vec_a)):
          vec_a[i] = (vec_a[i] + vec_b[i]);
      return vec_a;
  
  # Vector_sum(vec_a)
  def vector_sum(vec_a):
      output = 0;
      for i in range(len(vec_a)):
          output += vec_a[i];
      return output;
  
  # Vector_average(vec_a)
  def vector_average(vec_a):
      output = vector_sum(vec_a) / len(vec_a);
      return output;
  
  # Test Elementwise
  print("Elementwise_multiplication");
  vec_a = [1,2,3];
  vec_b = [1,2,3];
  ele_multiple = elementwise_multiplication(vec_a,vec_b);
  print(ele_multiple);
  
  print("Elementwise_addition");
  vec_a = [1,2,3];
  vec_b = [1,2,3];
  ele_addition = elementwise_addition(vec_a,vec_b);
  print(ele_addition);
  
  print("Vector_sum");
  vec_a = [1,2,3];
  vec_addition = vector_sum(vec_a);
  print(vec_addition);
  
  print("Vector_average");
  vec_a = [1,2,3];
  vec_average = vector_average(vec_a);
  print(vec_average);
  ```

## 3.7 使用NumPy实现

- 使用NumPy实现点积运算

  ```python
  import numpy as np;
  
  weights = np.array([0.1, 0.2, 0]);
  
  
  # Neural network code
  def neural_network(input, weights):
      pred = input.dot(weights);
      return pred;
  
  
  # Declaring variables
  toes = np.array([8.5, 9.5, 9.9, 9.0]);
  wlrec = np.array([0.65, 0.8, 0.8, 0.9]);
  nfans = np.array([1.2, 1.3, 0.5, 1.0]);
  
  
  # Test
  input = np.array([toes[0], wlrec[0], nfans[0]]);
  pred = neural_network(input, weights);
  print(pred);
  ```

## 3.8 预测多个输出

- 使用单个输入，实现多个输出

  ```python
  import numpy as np
  
  weights = np.array([0.3, 0.2, 0.9])
  
  
  # Neural network code
  def neural_network(input, weights):
      pred = ele_mul(input, weights)
      return pred
  
  
  # Ele_mul
  def ele_mul(number, vector):
      output = np.array([0, 0, 0])
      # check whether the len is the same
      assert (len(output) == len(vector));
      output = vector.dot(number)
      return output
  
  
  # Test
  wlrec = np.array([0.65, 0.8, 0.8, 0.9])
  input = wlrec[0]
  pred = neural_network(input, weights)
  print(pred)
  ```

## 3.9 多个输入输出

### Basic

- 可以将多个输出看成是影响每个输出节点的三个权重
- 针对输入，根据三个不同的权重来进行三次独立运算

### Implementation

```python
import numpy as np

weights = np.array([[0.1, 0.1, -0.3],  # hurt
                    [0.1, 0.2, 0.0],  # win
                    [0.0, 1.3, 0.1]])  # sad


# Neural network code
def neural_network(input, weights):
    output = weights.dot(input)
    return output;


# Test
toes = np.array([8.5, 9.5, 9.9, 9.0]);
wlrec = np.array([0.65, 0.8, 0.8, 0.9]);
nfans = np.array([1.2, 1.3, 0.5, 1.0]);
input = np.array([toes[0], wlrec[0], nfans[0]])
pred = neural_network(input, weights)
print(pred)
```

## 3.11 隐藏层

### Basic

- 输入和输出之间多了一层隐藏层，称为神经网络堆叠。
- 隐藏层根本意义是对前一层的数据分组。
- 如果两个数据点同时属于多个分组，则两个数据点相似；如果两个输入连接到各个隐藏层的权重相似，则两个输入相似。

### Implementation

```python
import numpy as np

# Weights
# toes %win #fans
ih_wgt = np.array([[0.1, 0.2, -0.1],  # hid[0]
                   [-0.1, 0.1, 0.9],  # hid[1]
                   [0.1, 0.4, 0.1]])  # hid[2]

# hid[0] hid[1] hid[2]
hp_wgt = np.array([[0.3, 1.1, -0.3],  # hurt
                   [0.1, 0.2, 0.0],  # win
                   [0.0, 1.3, 0.1]])  # sad


# Neural network code
def neural_network(input, weights):
    output = weights.dot(input)
    return output


# Test
toes = np.array([8.5, 9.5, 9.9, 9.0]);
wlrec = np.array([0.65, 0.8, 0.8, 0.9]);
nfans = np.array([1.2, 1.3, 0.5, 1.0]);
input = np.array([toes[0], wlrec[0], nfans[0]])
pred0 = neural_network(input, ih_wgt)
pred1 = neural_network(pred0, hp_wgt)
print(pred1)
```

## 3.12 NumPy入门

### Basci

- 任何逐元素操作（包括+,-,*,/）的两个变量必须具有相同数量的列，或者其中一个变量只有一列。

- 针对向量或者是矩阵进行点积操作，形状必须一致，左边矩阵的列数必须等于右边矩阵的行数。

- 在相邻的两个变量中，相邻的数字应该总是相同的。

  <!--1行4列的矩阵与4行3列的矩阵相乘，结果是1行3列-->

### Implementation

```python
import numpy as np

# Create matrix and vector
a = np.array([1, 3, 4])
b = np.array([2, 4, 5])
c = np.array([[3, 4, 77],
              [10, 3, 55]])
d = np.zeros((5,5))
e = np.random.rand(3,4)

# Test
print("a")
print(a)
print("")
print("b")
print(b)
print("")
print("c")
print(c)
print("")
print("d")
print(d)
print("")
print("e")
print(e)
```



























