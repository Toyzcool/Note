# 10.卷积神经网络概论：关于边与角的神经学习

- Principle：将许多小线性神经元层在各处重用。

- Rules

  - 卷积层有很多非常小的线性神经元层构成，
  - 每个线性层通常拥有少于25个输入和一个输出，
  - 每个小神经元层成为卷积核。

- **Implementation——Important!!!**

  1. 针对同一张图片8 * 8，使用四个卷积核。每个卷积核分别是3 * 3，也就是9个输入，1个输出。然后每次向右边移动一格像素，再次进行输入输出。到达最右边之后，回到最左边，然后向下移动一格像素，继续向右移动。

     <img src="assets/卷积1.jpg" style="zoom:20%;" />

  2. 每个卷积核都遍历完整张图片之后，就得到6 * 6的输出矩阵。因为有四个卷积核，所以有四个输出矩阵。

     <img src="assets/卷积2.jpg" style="zoom:20%;" />

  3. 根据第二步中的四个输出矩阵，池化成一个矩阵（汇总的矩阵每个格子都是取原四个矩阵对应的格子中的最大值）。作为信号向前传播到下一层。

     <img src="assets/卷积3.jpg" style="zoom:20%;" />

  4. 补充：第三步的汇总方式叫：最大池化（四个矩阵对应格子取最大值），还有求和池化（四个矩阵对应格子求和），平均池化（求和之后求平均值）。这层叫池化层（pooling层）。

  

- Structure

  ![image-20200211152926763](assets/structure.png)

  - 网络结构中有卷积层(convolution layer)，池化层(pooling layer)和全连接层(fully connected network)。
  - Implementation中分别使用了一次卷积层，一次池化层。

- **卷积计算方法——Important!!!**

  <!--image是原图片，filter为卷积核，feature map为卷积结果-->

  - Feature map中各个位置的计算方法

    ![image-20200211154454122](assets/calculate1.png)

    - feature map左上角第一个数字的计算过程

      ```shell
      fm[0][0] = i[0][0]*f[0][0] + i[0][1]*f[0][1] + i[0][2]*f[0][2] + i[1][0]*f[1][0] + i[1][1]*f[1][1] + i[1][2]*f[1][2] + i[2][0]*f[2][0] + i[2][1]*f[2][1] + i[2][2]*f[2][2] = 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1 = 4
      ```

      ```shell
      # Analyse
      因为步幅为1，所以每次只向右或者向下移动一格。Zero Padding为0，也就是在image周围没有加一圈0。
      ```

  - Feature map的大小计算方法

    ```
    W2 = (W1 - F + 2P) / S + 1
    H2 = (H1 - F + 2P) / S + 1
    ```

    ```shell
    # Analyse
    1.W2是卷积后Feature map的宽度；H2是卷积后Feature map的高度；
    2.W1是卷积前Image的宽度；H1是卷积前Image的高度；
    3.F是卷积核的宽度和高度；
    4.P是Zero Padding，也就是在Image周围补几圈0，常用于提取边缘部分的特征；
    5.S是步幅，也就是一次移动多少行或者多少列；
    ```

    